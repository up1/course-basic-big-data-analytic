{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4d85424-7bcc-411d-ba08-ba3595c64f55",
   "metadata": {},
   "source": [
    "## Workshop with SPARK DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b012ed-e4e2-4f99-b571-2e7fcf308cd0",
   "metadata": {},
   "source": [
    "Try by yourself\n",
    "* Reminder: documentation at https://spark.apache.org/docs/latest/api/python/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da4a50b-52a0-4e30-be52-7f920b52a986",
   "metadata": {},
   "source": [
    "## 1. Start session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0334fbb4-f76a-479b-b435-9b38e5a3e730",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/09/17 15:50:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/09/17 15:51:01 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/09/17 15:51:01 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "# Create the SparkSession\n",
    "# and read the dataset\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName(\"DataFrame Workshop\") \\\n",
    "        .config(\"spark.ui.showConsoleProgress\",\"false\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "online_retail_schema=\"InvoiceNo int, StockCode string, Description string, Quantity int,\\\n",
    "InvoiceDate timestamp,UnitPrice float,CustomerId int, Country string\"\n",
    "\n",
    "df = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"timestampFormat\", \"M/d/yyyy H:m\")\\\n",
    "        .csv(\"./data/online-retail-dataset.csv.gz\",\n",
    "             schema=online_retail_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dab0cd6-dd8b-4190-b334-297c209550bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-server-01:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DataFrame Workshop</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x75e1e6a98ec0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2905250-f71f-4437-972e-0942ba475098",
   "metadata": {},
   "source": [
    "## 2. Show 5 lines of the \"description\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a5ea337-3d98-4055-bdbf-3cd8b335ed07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+\n",
      "|description                        |\n",
      "+-----------------------------------+\n",
      "|WHITE HANGING HEART T-LIGHT HOLDER |\n",
      "|WHITE METAL LANTERN                |\n",
      "|CREAM CUPID HEARTS COAT HANGER     |\n",
      "|KNITTED UNION FLAG HOT WATER BOTTLE|\n",
      "|RED WOOLLY HOTTIE WHITE HEART.     |\n",
      "+-----------------------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df.select(\"description\").show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539f7b1a-e56c-4c67-a42b-0b3cfa2714fc",
   "metadata": {},
   "source": [
    "## 3. Find out in which month most invoices have been processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d49221b-0ef4-451b-9229-124ae714c0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|month(InvoiceDate)|count|\n",
      "+------------------+-----+\n",
      "|                 2|27707|\n",
      "|                 4|29916|\n",
      "|                 1|35147|\n",
      "|                 8|35284|\n",
      "|                 3|36748|\n",
      "|                 6|36874|\n",
      "|                 5|37030|\n",
      "|                 7|39518|\n",
      "|                 9|50226|\n",
      "|                10|60742|\n",
      "|                12|68006|\n",
      "|                11|84711|\n",
      "+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This shows how many line items have been processed per month\n",
    "\n",
    "from pyspark.sql.functions import month\n",
    "df.groupby(month(\"InvoiceDate\")).count().sort(\"count\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca2d7278-6374-4f16-aa26-272fe1ad252a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------+\n",
      "|month(InvoiceDate)|DistinctInvoices|\n",
      "+------------------+----------------+\n",
      "|                11|            3021|\n",
      "|                12|            2568|\n",
      "|                10|            2275|\n",
      "|                 9|            1994|\n",
      "|                 5|            1848|\n",
      "|                 6|            1683|\n",
      "|                 3|            1665|\n",
      "|                 7|            1657|\n",
      "|                 4|            1504|\n",
      "|                 8|            1456|\n",
      "|                 1|            1216|\n",
      "|                 2|            1174|\n",
      "+------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This shows how distinct invoices have been processed per month\n",
    "\n",
    "from pyspark.sql.functions import col, month, countDistinct\n",
    "\n",
    "(df\n",
    "   .groupBy(month('InvoiceDate'))\n",
    "   .agg(countDistinct('InvoiceNo').alias('DistinctInvoices'))\n",
    "   .orderBy(col('DistinctInvoices').desc())\n",
    "   .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff06742-cea2-4785-9dbf-3719ef5e5120",
   "metadata": {},
   "source": [
    "## 4. Filter the lines where the Quantity is more than 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b031356-9a9a-423a-81be-d085a3081e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerId|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536367|    84879|ASSORTED COLOUR B...|      32|2010-12-01 08:34:00|     1.69|     13047|United Kingdom|\n",
      "|   536370|    10002|INFLATABLE POLITI...|      48|2010-12-01 08:45:00|     0.85|     12583|        France|\n",
      "|   536370|    22492|MINI PAINT SET VI...|      36|2010-12-01 08:45:00|     0.65|     12583|        France|\n",
      "|   536371|    22086|PAPER CHAIN KIT 5...|      80|2010-12-01 09:00:00|     2.55|     13748|United Kingdom|\n",
      "|   536374|    21258|VICTORIAN SEWING ...|      32|2010-12-01 09:09:00|    10.95|     15100|United Kingdom|\n",
      "|   536376|    22114|HOT WATER BOTTLE ...|      48|2010-12-01 09:32:00|     3.45|     15291|United Kingdom|\n",
      "|   536376|    21733|RED HANGING HEART...|      64|2010-12-01 09:32:00|     2.55|     15291|United Kingdom|\n",
      "|   536378|    21212|PACK OF 72 RETROS...|     120|2010-12-01 09:37:00|     0.42|     14688|United Kingdom|\n",
      "|   536378|   85183B|CHARLIE & LOLA WA...|      48|2010-12-01 09:37:00|     1.25|     14688|United Kingdom|\n",
      "|   536378|   85071B|RED CHARLIE+LOLA ...|      96|2010-12-01 09:37:00|     0.38|     14688|United Kingdom|\n",
      "|   536381|    22719|GUMBALL MONOCHROM...|      36|2010-12-01 09:41:00|     1.06|     15311|United Kingdom|\n",
      "|   536382|    22381|TOY TIDY PINK POL...|      50|2010-12-01 09:45:00|     1.85|     16098|United Kingdom|\n",
      "|   536384|    84755|COLOUR GLASS T-LI...|      48|2010-12-01 09:53:00|     0.65|     18074|United Kingdom|\n",
      "|   536384|    22469|HEART OF WICKER S...|      40|2010-12-01 09:53:00|     1.45|     18074|United Kingdom|\n",
      "|   536384|    22470|HEART OF WICKER L...|      40|2010-12-01 09:53:00|     2.55|     18074|United Kingdom|\n",
      "|   536386|    84880|WHITE WIRE EGG HO...|      36|2010-12-01 09:57:00|     4.95|     16029|United Kingdom|\n",
      "|   536386|   85099C|JUMBO  BAG BAROQU...|     100|2010-12-01 09:57:00|     1.65|     16029|United Kingdom|\n",
      "|   536386|   85099B|JUMBO BAG RED RET...|     100|2010-12-01 09:57:00|     1.65|     16029|United Kingdom|\n",
      "|   536387|    79321|       CHILLI LIGHTS|     192|2010-12-01 09:58:00|     3.82|     16029|United Kingdom|\n",
      "|   536387|    22780|LIGHT GARLAND BUT...|     192|2010-12-01 09:58:00|     3.37|     16029|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.where(\"Quantity > 30\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf042fb-976d-4f63-8119-52253b7d2880",
   "metadata": {},
   "source": [
    "## 5. Show the four most sold items (by quantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bad23d8-acd9-4b9f-895f-10984646348b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+\n",
      "|         Description|totalQuantity|\n",
      "+--------------------+-------------+\n",
      "|WORLD WAR 2 GLIDE...|        53847|\n",
      "|JUMBO BAG RED RET...|        47363|\n",
      "|ASSORTED COLOUR B...|        36381|\n",
      "|      POPCORN HOLDER|        36334|\n",
      "+--------------------+-------------+\n",
      "only showing top 4 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc, asc, expr\n",
    "(df.groupBy(\"Description\")\n",
    "     .agg(expr(\"sum(Quantity) as totalQuantity\"))\n",
    "     .sort(\"totalQuantity\", ascending=False)\n",
    "     .show(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69464063-8911-4517-9d99-3f5d226db698",
   "metadata": {},
   "source": [
    "## 6. Why do these two operations return different results ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "003bf31a-0fe8-4ade-8a08-6f198c461a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22062\n",
      "+-------------------------+\n",
      "|count(DISTINCT InvoiceNo)|\n",
      "+-------------------------+\n",
      "|                    22061|\n",
      "+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.select(\"InvoiceNo\").distinct().count())\n",
    "\n",
    "from pyspark.sql.functions import countDistinct\n",
    "df.select(countDistinct(\"InvoiceNo\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78163740-3bc1-4d4c-8e76-8015d2841fb0",
   "metadata": {},
   "source": [
    "As you can see from the output of countDistinct, internally it runs count(DISTINCT, which excludes nulls.\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/sql/#count\n",
    "\n",
    "* count() Returns the total number of retrieved rows, including rows containing null\n",
    "* count(DISTINCT expr[, expr...]) - Returns the number of rows for which the supplied expression(s) are unique and non-null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fdb5e6-ac35-435f-8694-e798b3025dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
